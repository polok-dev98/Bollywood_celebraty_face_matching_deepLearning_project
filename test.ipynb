{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc7b83a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the library\n",
    "from keras_vggface.utils import preprocess_input\n",
    "from keras_vggface.vggface import VGGFace\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import cv2\n",
    "from mtcnn import MTCNN\n",
    "from PIL import Image\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1cf884e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = np.array(pickle.load(open('embedding.pkl','rb')))\n",
    "filenames = pickle.load(open('filenames.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb418527",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGGFace(model='resnet50',include_top=False,input_shape=(224,224,3),pooling='avg')\n",
    "detector = MTCNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a820f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_img(img_path):\n",
    "    \n",
    "    # load img -> face detection\n",
    "    sample_img = cv2.imread(img_path) # Set the sample image to test. \n",
    "    results = detector.detect_faces(sample_img)\n",
    "    x,y,width,height = results[0]['box']\n",
    "    face = sample_img[y:y+height,x:x+width]\n",
    "    \n",
    "    #show the sample img\n",
    "    position=(10,30)\n",
    "    img = cv2.imread(img_path)\n",
    "    img=cv2.resize(img,(400,400))\n",
    "    img=cv2.putText(img,\"Sample image\",position,cv2.FONT_HERSHEY_SIMPLEX, .7, (255,0,0), 3) \n",
    "    #cv2.imshow('output',img)\n",
    "    #cv2.waitKey(0)\n",
    "    \n",
    "    # extract its features\n",
    "    image = Image.fromarray(face)\n",
    "    image = image.resize((224,224))\n",
    "    face_array = np.asarray(image)\n",
    "    face_array = face_array.astype('float32')\n",
    "    expanded_img = np.expand_dims(face_array,axis=0)\n",
    "    preprocessed_img = preprocess_input(expanded_img)\n",
    "    result = model.predict(preprocessed_img).flatten()\n",
    "    \n",
    "    # calculate the similar score and sort it and grab the most similar img index.\n",
    "    similarity = []\n",
    "    for i in range(len(feature_list)):\n",
    "        similarity.append(cosine_similarity(result.reshape(1,-1),feature_list[i].reshape(1,-1))[0][0])\n",
    "        index_pos = sorted(list(enumerate(similarity)),reverse=True,key=lambda x:x[1])[0][0]\n",
    "    \n",
    "    # show the most PREDICTED img\n",
    "    predicted_actor =str(\"Looks like: \")+ \" \".join(filenames[index_pos].split('\\\\')[1].split('_'))\n",
    "    temp_img = cv2.imread(filenames[index_pos])\n",
    "    temp_img=cv2.resize(temp_img,(400,400))\n",
    "    temp_img=cv2.putText(temp_img,predicted_actor,position,cv2.FONT_HERSHEY_SIMPLEX, .7, (255,0,0), 3)\n",
    "    combine = cv2.hconcat([img,temp_img])\n",
    "    cv2.imshow('output',combine)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaa104d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 277ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 117ms/step\n",
      "1/1 [==============================] - 0s 134ms/step\n",
      "1/1 [==============================] - 1s 928ms/step\n"
     ]
    }
   ],
   "source": [
    "#set the test image ------> \"sample/img name of the sample folder\"\n",
    "\n",
    "#call the function\n",
    "upload_img(\"sample/srk1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ab1c6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
